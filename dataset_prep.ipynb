{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparations before running Evaluation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minimal_example\n",
    "\n",
    "* Simply resize all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "for path, dirnames, filenames in os.walk(\"./data/minimal_example\"):\n",
    "    for fn in filenames:\n",
    "        im = Image.open(f\"{path}/{fn}\")\n",
    "        im = im.resize((224, 224))\n",
    "        im.save(f\"{path}/{fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynthNet - Rendered Datasets from Topex CAD files\n",
    "\n",
    "1. Prepend 'synth_' to image names and fix appended index with zeros\n",
    "2. Move images into class label directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "IN_DIR = '/mnt/c/Users/denni/Desktop/work/7054-12-300-l_drucker_se_su_st_st_512_32/render'\n",
    "# IN_DIR = '/home/dennis/Desktop/work/7054-12-300-l_drucker_se_su_st_st_512_32/render'\n",
    "OUT_DIR = 'data/synthnet/train/7054-12-300-l_drucker_se_su_st_st_512_32'\n",
    "\n",
    "def prepare_synthnet_synth_imgs(in_dir: str, out_dir: str) -> None:\n",
    "    os.makedirs(f\"{out_dir}/images\", exist_ok=True)\n",
    "    os.makedirs(f\"{out_dir}/assets\", exist_ok=True)\n",
    "    synth_ims = os.listdir(f'{in_dir}')\n",
    "    for i, im_name in enumerate(synth_ims):\n",
    "        im_path = f'{in_dir}/{im_name}'\n",
    "        im_class = '_'.join(im_name.split('_')[:-1])\n",
    "        im_oid = 1\n",
    "        im_label_i = int(im_name.split('_')[-1].split('.')[0])\n",
    "\n",
    "        im_name_new = f'train_{im_class}_{im_oid:04d}_{im_label_i:04d}.png'\n",
    "        dest_path = f'{out_dir}/images/{im_class}/{im_class}_{im_oid:04d}/{im_name_new}'.lower()\n",
    "\n",
    "        os.makedirs(f'{out_dir}/images/{im_class}/{im_class}_{im_oid:04d}'.lower(), exist_ok=True)\n",
    "        shutil.copy(im_path, dest_path)\n",
    "\n",
    "prepare_synthnet_synth_imgs(IN_DIR, OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynthNet - bounding box annotated topex-real-N datasets\n",
    "\n",
    "1.  Parse images from annotations.json file\n",
    "2.  Get objects' bounding box dimensions\n",
    "3.  Crop image with bounding box dimensions and expand the smaller side to get a rectangular crop \n",
    "    or expand to image dimensions if the image is too small. \n",
    "4.  Resize image to target_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from typing import Tuple\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "IN_DIR = '/home/dennis/Desktop/synthnet/topex-real-123'\n",
    "OUT_DIR = 'data/synthnet/real/topex-real-123_pb_256/images'\n",
    "TARGET_SIZE = (256, 256) \n",
    "CROP_OPTION = 'padding_black' # one of ['resize', 'padding_black']\n",
    "\n",
    "# NOTE: Script does not handle duplicate part_ids at the moment!\n",
    "def prepare_synthnet_topex_real_imgs(in_dir: str, out_dir: str, target_size: Tuple, crop_option: str) -> None:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    with open(f'{in_dir}/annotations.json', 'r', encoding='utf-8') as f:\n",
    "        annotations = json.load(f)\n",
    "\n",
    "    for annotation in annotations:\n",
    "        for annotation_label in annotation['label']:\n",
    "            im_label = annotation_label['rectanglelabels'][0]\n",
    "\n",
    "            im_name = annotation['image'].split('/')[-1]\n",
    "            im_path = f'{in_dir}/{im_label}/{im_name}'\n",
    "            if not os.path.exists(im_path):\n",
    "                continue\n",
    "            im = Image.open(im_path)\n",
    "            # Rotate image as expected\n",
    "            im = ImageOps.exif_transpose(im)\n",
    "\n",
    "            # Crop\n",
    "            im_w, im_h = annotation_label['original_width'], annotation_label['original_height']\n",
    "            # Bounding box position and size is given in percent (0-100)\n",
    "            bb_x = int((annotation_label['x'] / 100) * im_w)\n",
    "            bb_y = int((annotation_label['y'] / 100) * im_h)\n",
    "            bb_w = int((annotation_label['width'] / 100) * im_w)\n",
    "            bb_h = int((annotation_label['height'] / 100) * im_h)\n",
    "\n",
    "            # get rectangular bounding box image dimension in px, expand narrow axis to wider axis size\n",
    "            if bb_w >= bb_h:\n",
    "                d = (bb_w - bb_h) / 2\n",
    "                left = bb_x\n",
    "                top = bb_y - d\n",
    "                right = bb_x + bb_w\n",
    "                bottom = bb_y + bb_h + d\n",
    "            if bb_w < bb_h:\n",
    "                d = (bb_h - bb_w) / 2\n",
    "                left = bb_x - d\n",
    "                top = bb_y\n",
    "                right = bb_x + bb_w + d\n",
    "                bottom = bb_y + bb_h\n",
    "\n",
    "            # Limit crop to image dimensions if !padding\n",
    "            if crop_option == 'resize':\n",
    "                w, h = im.size\n",
    "                left = 0 if left < 0 else left\n",
    "                top = 0 if top < 0 else top\n",
    "                right = w if right > w else right\n",
    "                bottom = h if bottom > h else bottom\n",
    "\n",
    "            im = im.crop((int(left), int(top), int(right), int(bottom)))\n",
    "            im = im.resize(target_size)\n",
    "\n",
    "            os.makedirs(f'{out_dir}/{im_label}'.lower(), exist_ok=True)\n",
    "            im.save(f'{out_dir}/{im_label}/test_{im_name}'.lower())\n",
    "\n",
    "prepare_synthnet_topex_real_imgs(IN_DIR, OUT_DIR, TARGET_SIZE, CROP_OPTION)\n",
    "# for path, dns, fns in os.walk(\"./data/synthnet/test/topex-real-123_pb_256/images\"):\n",
    "#     for fn in fns:\n",
    "#         new_fn = f'test{fn[4:]}'\n",
    "#         shutil.move(f'{path}/{fn}', f\"{path}/{new_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShapeNetCore17 <-> ILSVRC\n",
    "\n",
    "We use renders of **ShapeNetCore objects** from 17 classes as train set and to build the search index and connect them to **real fotos from the ImageNet Dataset** using their **synset connections**\n",
    "\n",
    "```\n",
    "02747177 ['ashcan', 'trash can', 'garbage can', 'wastebin', 'ash bin', 'ash-bin', 'ashbin', 'dustbin', 'trash barrel', 'trash bin']\n",
    "02808440 ['bathtub', 'bathing tub', 'bath', 'tub']\n",
    "02843684 ['birdhouse']\n",
    "02992529 ['cellular telephone', 'cellular phone', 'cellphone', 'cell', 'mobile phone']\n",
    "03085013 ['computer keyboard', 'keypad']\n",
    "03207941 ['dishwasher', 'dish washer', 'dishwashing machine']\n",
    "03337140 ['file', 'file cabinet', 'filing cabinet']\n",
    "03642806 ['laptop', 'laptop computer']\n",
    "03691459 ['loudspeaker', 'speaker', 'speaker unit', 'loudspeaker system', 'speaker system']\n",
    "03710193 ['mailbox', 'letter box']\n",
    "03759954 ['microphone', 'mike']\n",
    "03761084 ['microwave', 'microwave oven']\n",
    "03938244 ['pillow']\n",
    "03991062 ['pot', 'flowerpot']\n",
    "04074963 ['remote control', 'remote']\n",
    "04330267 ['stove']\n",
    "04554684 ['washer', 'automatic washer', 'washing machine']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "IN_DIR = '/home/dennis/Desktop/sn17_renders'\n",
    "OUT_DIR = 'data/sn17ilsvrc/train'\n",
    "\n",
    "# TODO update \n",
    "# def prepare_synthnet_synth_imgs(in_dir: str, out_dir: str) -> None:\n",
    "#     os.makedirs(f\"{out_dir}/images\", exist_ok=True)\n",
    "#     os.makedirs(f\"{out_dir}/assets\", exist_ok=True)\n",
    "#     synth_ims = os.listdir(f'{in_dir}')\n",
    "#     for i, im_name in enumerate(synth_ims):\n",
    "#         im_path = f'{in_dir}/{im_name}'\n",
    "#         im_class = '_'.join(im_name.split('_')[:-1])\n",
    "#         im_oid = 1\n",
    "#         im_label_i = int(im_name.split('_')[-1].split('.')[0])\n",
    "\n",
    "#         im_name_new = f'train_{im_class}_{im_oid:04d}_{im_label_i:04d}.png'\n",
    "#         dest_path = f'{out_dir}/images/{im_class}/{im_oid:04d}/{im_name_new}'.lower()\n",
    "\n",
    "#         os.makedirs(f'{out_dir}/images/{im_class}/{im_oid:04d}'.lower(), exist_ok=True)\n",
    "#         shutil.copy(im_path, dest_path)\n",
    "\n",
    "# prepare_synthnet_synth_imgs(IN_DIR, OUT_DIR)\n",
    "\n",
    "def prepare_synthnet_synth_imgs(in_dir: str, out_dir: str) -> None:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    synth_ims = os.listdir(f'{in_dir}/render')\n",
    "    for i, im_name in enumerate(synth_ims):\n",
    "        im_path = f'{in_dir}/render/{im_name}'\n",
    "        \n",
    "        im_entity = '_'.join(im_name.split('_')[:-1])\n",
    "        im_entity_i = int(im_name.split('_')[-1].split('.')[0])\n",
    "\n",
    "        for synset in os.listdir('../notebooks/data/synthnet/sn17'):\n",
    "            if os.path.isdir(f'../notebooks/data/synthnet/sn17/{synset}'):\n",
    "                for entity in os.listdir(f'../notebooks/data/synthnet/sn17/{synset}'):\n",
    "                    if entity == im_entity:\n",
    "                        im_label = synset\n",
    "\n",
    "        im_name_new = f'synth_{im_entity}_{im_entity_i:04d}.png'\n",
    "        dest_path = f'{out_dir}/{im_label}/{im_name_new}'.lower()\n",
    "\n",
    "        # print(im_entity)\n",
    "        os.makedirs(f'{out_dir}/{im_label}'.lower(), exist_ok=True)\n",
    "        shutil.copy(im_path, dest_path)\n",
    "\n",
    "prepare_synthnet_synth_imgs(IN_DIR, OUT_DIR)\n",
    "# for path, dns, fns in os.walk(\"./data/sn17ilsvrc/train/shapenetcore_17/images\"):\n",
    "#     for fn in fns:\n",
    "#         obj = fn.split('_')[1]\n",
    "#         os.makedirs(f'{path}/{obj}'.lower(), exist_ok=True)\n",
    "#         new_fn = f'train{fn[5:]}'\n",
    "#         shutil.move(f'{path}/{fn}', f\"{path}/{obj}/{new_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ILSVRC2012_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import untangle\n",
    "\n",
    "classes = [\n",
    "    'n02747177', 'n02808440', 'n02843684', 'n02992529', 'n03085013', 'n03207941', 'n03337140', 'n03642806', 'n03691459',\n",
    "    'n03710193', 'n03759954', 'n03761084', 'n03938244', 'n03991062', 'n04074963', 'n04330267', 'n04554684'\n",
    "]\n",
    "in_root = \"./data/synthnet/ilsvrc_val_17_prep\"\n",
    "\n",
    "for synset in os.listdir(f'{in_root}/images'):\n",
    "    for im_name in os.listdir(f'{in_root}/images/{synset}'):\n",
    "        print(im_name)\n",
    "        print(f'{in_root}/annotations/{synset}/{im_name[:-5]}.xml')\n",
    "        annotation = untangle.parse(f'{in_root}/annotations/{synset}/{im_name[:-5]}.xml')\n",
    "        n = 1\n",
    "        for ob in annotation.annotation.object:\n",
    "            ann_synset = ob.name.cdata\n",
    "            w, h = annotation.annotation.size.width.cdata, annotation.annotation.size.height.cdata\n",
    "            left, right, top, bottom = int(ob.bndbox.xmin.cdata), int(ob.bndbox.xmax.cdata), int(\n",
    "                ob.bndbox.ymin.cdata), int(ob.bndbox.ymax.cdata)\n",
    "            print(ann_synset)\n",
    "            if ann_synset in classes:\n",
    "                bb_w = right - left\n",
    "                bb_h = bottom - top\n",
    "\n",
    "                im = Image.open(f'{in_root}/images/{synset}/{im_name}')\n",
    "                # get rectangular bounding box image dimension in px, expand narrow axis to wider axis size\n",
    "                if bb_w >= bb_h:\n",
    "                    d = (bb_w - bb_h) / 2\n",
    "                    left = left\n",
    "                    top = top - d\n",
    "                    right = left + bb_w\n",
    "                    bottom = top + bb_h + d * 2\n",
    "                if bb_w < bb_h:\n",
    "                    d = (bb_h - bb_w) / 2\n",
    "                    left = left - d\n",
    "                    top = top\n",
    "                    right = left + bb_w + d * 2\n",
    "                    bottom = top + bb_h\n",
    "                im = im.crop((int(left), int(top), int(right), int(bottom)))\n",
    "                im = im.resize((256, 256))\n",
    "\n",
    "                ilsvrc_id = im_name[:-5].split(\"_\")[-1]\n",
    "                out_name = f'{ilsvrc_id}_{n}.png'\n",
    "                out_dir = f\"./data/synthnet/ilsvrc_val_17_resized/{synset}\"\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "                im.save(f'{out_dir}/{out_name}')\n",
    "\n",
    "                n = n + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MI3DOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MI3DOR - TRAIN SET - SYNTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "ROOT=\"/home/dennis/Desktop/work/MI3DOR/view/train\"\n",
    "OUT=\"./data/mi3dor/train_synth/images\"\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "for classname in os.listdir(ROOT):\n",
    "    for entityname in os.listdir(f'{ROOT}/{classname}'):\n",
    "        os.makedirs(f'{OUT}/{classname}/{entityname}', exist_ok=True)\n",
    "        for path, dirnames, filenames in os.walk(f'{ROOT}/{classname}/{entityname}'):\n",
    "            for fname in filenames:\n",
    "                shutil.copy(f'{path}/{fname}', f'{OUT}/{classname}/{entityname}/{fname}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MI3DOR - TEST SET - REAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "ROOT=\"/home/dennis/Desktop/work/MI3DOR/image/test\"\n",
    "OUT=\"./data/mi3dor/test_real/images\"\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "TARGET_SIZE = (224, 224)\n",
    "\n",
    "for classname in os.listdir(ROOT):\n",
    "    os.makedirs(f'{OUT}/{classname}', exist_ok=True)\n",
    "    for path, dirnames, filenames in os.walk(f'{ROOT}/{classname}'):\n",
    "        for fname in filenames:\n",
    "            im = Image.open(f'{path}/{fname}')\n",
    "            im = im.resize(TARGET_SIZE)\n",
    "            im.save(f'{OUT}/{classname}/{fname}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelNet10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "IN_DIR = \"/mnt/c/Users/denni/Desktop/work/modelnet10_st_st_none_st_256/render\"\n",
    "OUT = \"./data/modelnet10\"\n",
    "for path, dirnames, filenames in os.walk(f'{IN_DIR}'):\n",
    "    for fname in filenames:\n",
    "        fname_split = fname.split(\"_\")\n",
    "        split = fname_split[0]\n",
    "        label = fname_split[1]\n",
    "        mesh = f'{fname_split[1]}_{fname_split[2]}'\n",
    "        # We just hack this in as 'night_stand' is the only two-word-class using _\n",
    "        if label == 'night':\n",
    "            label = f'{fname_split[1]}_{fname_split[2]}'\n",
    "            mesh = f'{fname_split[1]}_{fname_split[2]}_{fname_split[3]}'\n",
    "        n_img = fname_split[-1].split('.')[0]\n",
    "        ext = fname_split[-1].split('.')[1]\n",
    "        if split == 'train':\n",
    "            out_dir = f'{OUT}/{split}/images/{label}/{mesh}'\n",
    "        if split == 'test':\n",
    "            out_dir = f'{OUT}/{split}/images/{label}'\n",
    "        out_path = f'{out_dir}/{fname}'\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        shutil.copy(f'{path}/{fname}', out_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VisDA 2017"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Huggingface Imagefolder format -> retrieval pipeline format (with mesh ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/datasets/visda2017_meshes/train/images/skateboard/src_1_04225987_5c55e6b6708f730d758f6def7204bd6b//src_1_04225987_5c55e6b6708f730d758f6def7204bd6b/src_1_04225987_5c55e6b6708f730d758f6def7204bd6b__146_236_150_train.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m out_dir \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mOUT\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00msplit\u001b[39m}\u001b[39;00m\u001b[39m/images/\u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmesh\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m os\u001b[39m.\u001b[39mmakedirs(out_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m shutil\u001b[39m.\u001b[39;49mcopy(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mpath\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mfname\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mout_dir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mmesh\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mfname\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310-evaluation-pipeline/lib/python3.10/shutil.py:417\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(dst):\n\u001b[1;32m    416\u001b[0m     dst \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dst, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(src))\n\u001b[0;32m--> 417\u001b[0m copyfile(src, dst, follow_symlinks\u001b[39m=\u001b[39;49mfollow_symlinks)\n\u001b[1;32m    418\u001b[0m copymode(src, dst, follow_symlinks\u001b[39m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    419\u001b[0m \u001b[39mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m~/miniconda3/envs/py310-evaluation-pipeline/lib/python3.10/shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(src, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(dst, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m             \u001b[39m# macOS\u001b[39;00m\n\u001b[1;32m    258\u001b[0m             \u001b[39mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[1;32m    259\u001b[0m                 \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/datasets/visda2017_meshes/train/images/skateboard/src_1_04225987_5c55e6b6708f730d758f6def7204bd6b//src_1_04225987_5c55e6b6708f730d758f6def7204bd6b/src_1_04225987_5c55e6b6708f730d758f6def7204bd6b__146_236_150_train.png'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "IN_DIR = \"/home/dennis/projects/feature-extractor-finetuning/data/visda2017\"\n",
    "OUT = \"./data/datasets/visda2017_meshes\"\n",
    "for path, dirnames, filenames in os.walk(f'{IN_DIR}'):\n",
    "    for fname in filenames:\n",
    "        psplit = path.split('/')\n",
    "        label = psplit[-1]\n",
    "        split = psplit[-2]\n",
    "        if split == 'train':\n",
    "            fsplit = fname.split('__')\n",
    "            mesh = fsplit[0]\n",
    "            \n",
    "            out_dir = f\"{OUT}/{split}/images/{label}/{mesh}/\"\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            shutil.copy(f\"{path}/{fname}\", f\"{out_dir}/{fname}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val/test\n",
    "\n",
    "add labels to dir structure from image_list.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'aeroplane', 1: 'bicycle', 2: 'bus', 3: 'car', 4: 'horse', 5: 'knife', 6: 'motorcycle', 7: 'person', 8: 'plant', 9: 'skateboard', 10: 'train', 11: 'truck'}\n",
      "{'aeroplane': 0, 'bicycle': 1, 'bus': 2, 'car': 3, 'horse': 4, 'knife': 5, 'motorcycle': 6, 'person': 7, 'plant': 8, 'skateboard': 9, 'train': 10, 'truck': 11}\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import pandas as pd\n",
    "\n",
    "# DATASET_NAME = 'visda2017'\n",
    "# DS_DIR = f'data/datasets/{DATASET_NAME}/test/images'\n",
    "\n",
    "# OUT_ROOT = f'data/{DATASET_NAME}'\n",
    "\n",
    "# id2label = {id: label for id, label in enumerate(sorted(os.listdir(f\"data/datasets/{DATASET_NAME}/val/images\")))}\n",
    "# label2id = {label: id for id, label in id2label.items()}\n",
    "\n",
    "# print(id2label)\n",
    "# print(label2id)\n",
    "\n",
    "# df = pd.read_csv(f\"data/datasets/{DATASET_NAME}/test/assets/image_list.txt\", sep=\" \", header=None)\n",
    "\n",
    "# for path, dns, fns in os.walk(DS_DIR):\n",
    "#     for fn in fns:\n",
    "#         trunk = path.split(\"/\")[-1]\n",
    "#         label_id = df.loc[df[0] == f'{trunk}/{fn}'][1].values[0]\n",
    "#         label = id2label[label_id]\n",
    "#         out = f'{OUT_ROOT}/test/images/{label}/{fn[:-4]}_{label}_test.jpg'\n",
    "#         os.makedirs(f'{OUT_ROOT}/test/images/{label}', exist_ok=True)\n",
    "#         shutil.move(f'{path}/{fn}', out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310-evaluation-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a94912fb230aae3242d5ee91e35fe433a84de386757084e9f23369d2771ea31c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
